{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e445eb2-b1d9-4914-91c4-630518091073",
   "metadata": {},
   "source": [
    "Sulla base di https://github.com/langchain-ai/research-rabbit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "dec7ab00-e64d-4417-9bcd-f6783356b8de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "os.environ[\"TAVILY_API_KEY\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ab38a097-91e3-4532-b88c-88036b54ff7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dataclasses import dataclass, field, fields\n",
    "from typing import Any, Optional\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from typing_extensions import Annotated\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class Configuration:\n",
    "    \"\"\"The configurable fields for the research assistant.\"\"\"\n",
    "    max_web_research_loops: int = 3\n",
    "    local_llm: str = \"llama3.2\"\n",
    "\n",
    "    @classmethod\n",
    "    def from_runnable_config(\n",
    "        cls, config: Optional[RunnableConfig] = None\n",
    "    ) -> \"Configuration\":\n",
    "        \"\"\"Create a Configuration instance from a RunnableConfig.\"\"\"\n",
    "        configurable = (\n",
    "            config[\"configurable\"] if config and \"configurable\" in config else {}\n",
    "        )\n",
    "        values: dict[str, Any] = {\n",
    "            f.name: os.environ.get(f.name.upper(), configurable.get(f.name))\n",
    "            for f in fields(cls)\n",
    "            if f.init\n",
    "        }\n",
    "        return cls(**{k: v for k, v in values.items() if v})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "efa57533-f053-4909-a744-ec84d253575a",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_writer_instructions=\"\"\"Your goal is to generate targeted web search query.\n",
    "\n",
    "The query will gather information related to a specific topic.\n",
    "\n",
    "Topic:\n",
    "{research_topic}\n",
    "\n",
    "Return your query as a JSON object:\n",
    "{{\n",
    "    \"query\": \"string\",\n",
    "    \"aspect\": \"string\",\n",
    "    \"rationale\": \"string\"\n",
    "}}\n",
    "\"\"\"\n",
    "\n",
    "summarizer_instructions=\"\"\"Your goal is to generate a high-quality summary of the web search results.\n",
    "\n",
    "When EXTENDING an existing summary:\n",
    "1. Seamlessly integrate new information without repeating what's already covered\n",
    "2. Maintain consistency with the existing content's style and depth\n",
    "3. Only add new, non-redundant information\n",
    "4. Ensure smooth transitions between existing and new content\n",
    "\n",
    "When creating a NEW summary:\n",
    "1. Highlight the most relevant information from each source\n",
    "2. Provide a concise overview of the key points related to the report topic\n",
    "3. Emphasize significant findings or insights\n",
    "4. Ensure a coherent flow of information\n",
    "\n",
    "In both cases:\n",
    "- Focus on factual, objective information\n",
    "- Maintain a consistent technical depth\n",
    "- Avoid redundancy and repetition\n",
    "- DO NOT use phrases like \"based on the new results\" or \"according to additional sources\"\n",
    "- DO NOT add a preamble like \"Here is an extended summary ...\" Just directly output the summary.\n",
    "- DO NOT add a References or Works Cited section.\n",
    "\"\"\"\n",
    "\n",
    "reflection_instructions = \"\"\"You are an expert research assistant analyzing a summary about {research_topic}.\n",
    "\n",
    "Your tasks:\n",
    "1. Identify knowledge gaps or areas that need deeper exploration\n",
    "2. Generate a follow-up question that would help expand your understanding\n",
    "3. Focus on technical details, implementation specifics, or emerging trends that weren't fully covered\n",
    "\n",
    "Ensure the follow-up question is self-contained and includes necessary context for web search.\n",
    "\n",
    "Return your analysis as a JSON object:\n",
    "{{ \n",
    "    \"knowledge_gap\": \"string\",\n",
    "    \"follow_up_query\": \"string\"\n",
    "}}\"\"\"\n",
    "\n",
    "translator_instructions=\"\"\"Your goal is to translate the summary given into italian language.\n",
    "Do not translate links in sources section.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f77b5ecf-f5ab-47ce-a54e-f0095d11336c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator\n",
    "from dataclasses import dataclass, field\n",
    "from typing_extensions import TypedDict, Annotated\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryState:\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "    search_query: str = field(default=None) # Search query\n",
    "    web_research_results: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    sources_gathered: Annotated[list, operator.add] = field(default_factory=list) \n",
    "    research_loop_count: int = field(default=0) # Research loop count\n",
    "    running_summary: str = field(default=None) # Final report\n",
    "    italian_summary: str = field(default=None) # Final report\n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateInput(TypedDict):\n",
    "    research_topic: str = field(default=None) # Report topic     \n",
    "\n",
    "@dataclass(kw_only=True)\n",
    "class SummaryStateOutput(TypedDict):\n",
    "    italian_summary: str = field(default=None) # Final report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "72884fcb-c41b-48b7-a607-59a592214fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tavily import TavilyClient\n",
    "\n",
    "def deduplicate_and_format_sources(search_response, max_tokens_per_source, include_raw_content=True):\n",
    "    \"\"\"\n",
    "    Takes either a single search response or list of responses from Tavily API and formats them.\n",
    "    Limits the raw_content to approximately max_tokens_per_source.\n",
    "    include_raw_content specifies whether to include the raw_content from Tavily in the formatted string.\n",
    "    \n",
    "    Args:\n",
    "        search_response: Either:\n",
    "            - A dict with a 'results' key containing a list of search results\n",
    "            - A list of dicts, each containing search results\n",
    "            \n",
    "    Returns:\n",
    "        str: Formatted string with deduplicated sources\n",
    "    \"\"\"\n",
    "    # Convert input to list of results\n",
    "    if isinstance(search_response, dict):\n",
    "        sources_list = search_response['results']\n",
    "    elif isinstance(search_response, list):\n",
    "        sources_list = []\n",
    "        for response in search_response:\n",
    "            if isinstance(response, dict) and 'results' in response:\n",
    "                sources_list.extend(response['results'])\n",
    "            else:\n",
    "                sources_list.extend(response)\n",
    "    else:\n",
    "        raise ValueError(\"Input must be either a dict with 'results' or a list of search results\")\n",
    "    \n",
    "    # Deduplicate by URL\n",
    "    unique_sources = {}\n",
    "    for source in sources_list:\n",
    "        if source['url'] not in unique_sources:\n",
    "            unique_sources[source['url']] = source\n",
    "    \n",
    "    # Format output\n",
    "    formatted_text = \"Sources:\\n\\n\"\n",
    "    for i, source in enumerate(unique_sources.values(), 1):\n",
    "        formatted_text += f\"Source {source['title']}:\\n===\\n\"\n",
    "        formatted_text += f\"URL: {source['url']}\\n===\\n\"\n",
    "        formatted_text += f\"Most relevant content from source: {source['content']}\\n===\\n\"\n",
    "        if include_raw_content:\n",
    "            # Using rough estimate of 4 characters per token\n",
    "            char_limit = max_tokens_per_source * 4\n",
    "            # Handle None raw_content\n",
    "            raw_content = source.get('raw_content', '')\n",
    "            if raw_content is None:\n",
    "                raw_content = ''\n",
    "                print(f\"Warning: No raw_content found for source {source['url']}\")\n",
    "            if len(raw_content) > char_limit:\n",
    "                raw_content = raw_content[:char_limit] + \"... [truncated]\"\n",
    "            formatted_text += f\"Full source content limited to {max_tokens_per_source} tokens: {raw_content}\\n\\n\"\n",
    "                \n",
    "    return formatted_text.strip()\n",
    "\n",
    "def format_sources(search_results):\n",
    "    \"\"\"Format search results into a bullet-point list of sources.\n",
    "    \n",
    "    Args:\n",
    "        search_results (dict): Tavily search response containing results\n",
    "        \n",
    "    Returns:\n",
    "        str: Formatted string with sources and their URLs\n",
    "    \"\"\"\n",
    "    return '\\n'.join(\n",
    "        f\"* {source['title']} : {source['url']}\"\n",
    "        for source in search_results['results']\n",
    "    )\n",
    "\n",
    "\n",
    "def tavily_search(query, include_raw_content=True, max_results=3):\n",
    "    \"\"\" Search the web using the Tavily API.\n",
    "    \n",
    "    Args:\n",
    "        query (str): The search query to execute\n",
    "        include_raw_content (bool): Whether to include the raw_content from Tavily in the formatted string\n",
    "        max_results (int): Maximum number of results to return\n",
    "        \n",
    "    Returns:\n",
    "        dict: Tavily search response containing:\n",
    "            - results (list): List of search result dictionaries, each containing:\n",
    "                - title (str): Title of the search result\n",
    "                - url (str): URL of the search result\n",
    "                - content (str): Snippet/summary of the content\n",
    "                - raw_content (str): Full content of the page if available\"\"\"\n",
    "     \n",
    "#    tavily_client = TavilyClient()\n",
    "    tavily_client = TavilyClient(api_key=os.environ[\"TAVILY_API_KEY\"])\n",
    "    return tavily_client.search(query, \n",
    "                         max_results=max_results, \n",
    "                         include_raw_content=include_raw_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "1b747fa8-39bb-43b0-a201-4e0aa39e07c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "from typing_extensions import Literal\n",
    "\n",
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_ollama import ChatOllama\n",
    "from langgraph.graph import START, END, StateGraph\n",
    "\n",
    "# LLM\n",
    "llm = ChatOllama(model=Configuration.local_llm, temperature=0)\n",
    "llm_json_mode = ChatOllama(model=Configuration.local_llm, temperature=0, format=\"json\")\n",
    "\n",
    "# Nodes   \n",
    "def generate_query(state: SummaryState):\n",
    "    \"\"\" Generate a query for web search \"\"\"\n",
    "    \n",
    "    print(\"genero la query\")\n",
    "    # Format the prompt\n",
    "    query_writer_instructions_formatted = query_writer_instructions.format(research_topic=state.research_topic)\n",
    "\n",
    "    # Generate a query\n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=query_writer_instructions_formatted),\n",
    "        HumanMessage(content=f\"Generate a query for web search:\")]\n",
    "    )   \n",
    "    query = json.loads(result.content)\n",
    "    print(f\"Query generata : {query}\")\n",
    "\n",
    "    \n",
    "    return {\"search_query\": query['query']}\n",
    "\n",
    "def web_research(state: SummaryState):\n",
    "    \"\"\" Gather information from the web \"\"\"\n",
    "\n",
    "    print(\"Effettuo la ricerca\")\n",
    "    # Search the web\n",
    "    search_results = tavily_search(state.search_query, include_raw_content=True, max_results=1)\n",
    "    \n",
    "    # Format the sources\n",
    "    search_str = deduplicate_and_format_sources(search_results, max_tokens_per_source=1000)\n",
    "    print(f\"Esito ricerca : {search_str}\")\n",
    "    return {\"sources_gathered\": [format_sources(search_results)], \"research_loop_count\": state.research_loop_count + 1, \"web_research_results\": [search_str]}\n",
    "\n",
    "def summarize_sources(state: SummaryState):\n",
    "    \"\"\" Summarize the gathered sources \"\"\"\n",
    "\n",
    "    print(\"Effettuo sommario\")\n",
    "    # Existing summary\n",
    "    existing_summary = state.running_summary\n",
    "\n",
    "    # Most recent web research\n",
    "    most_recent_web_research = state.web_research_results[-1]\n",
    "\n",
    "    # Build the human message\n",
    "    if existing_summary:\n",
    "        human_message_content = (\n",
    "            f\"Extend the existing summary: {existing_summary}\\n\\n\"\n",
    "            f\"Include new search results: {most_recent_web_research} \"\n",
    "            f\"That addresses the following topic: {state.research_topic}\"\n",
    "        )\n",
    "    else:\n",
    "        human_message_content = (\n",
    "            f\"Generate a summary of these search results: {most_recent_web_research} \"\n",
    "            f\"That addresses the following topic: {state.research_topic}\"\n",
    "        )\n",
    "\n",
    "    # Run the LLM\n",
    "    result = llm.invoke(\n",
    "        [SystemMessage(content=summarizer_instructions),\n",
    "        HumanMessage(content=human_message_content)]\n",
    "    )\n",
    "\n",
    "    running_summary = result.content\n",
    "    print(f\"Sommario : {running_summary}\")\n",
    "    return {\"running_summary\": running_summary}\n",
    "\n",
    "def reflect_on_summary(state: SummaryState):\n",
    "    \"\"\" Reflect on the summary and generate a follow-up query \"\"\"\n",
    "\n",
    "    print(\"Ragiono sul sommario\")\n",
    "    # Generate a query\n",
    "    result = llm_json_mode.invoke(\n",
    "        [SystemMessage(content=reflection_instructions.format(research_topic=state.research_topic)),\n",
    "        HumanMessage(content=f\"Identify a knowledge gap and generate a follow-up web search query based on our existing knowledge: {state.running_summary}\")]\n",
    "    )   \n",
    "    follow_up_query = json.loads(result.content)\n",
    "\n",
    "    # Overwrite the search query\n",
    "    return {\"search_query\": follow_up_query['follow_up_query']}\n",
    "\n",
    "def finalize_summary(state: SummaryState):\n",
    "    \"\"\" Finalize the summary \"\"\"\n",
    "\n",
    "    print(\"Finalizzo il sommario\")\n",
    "    # Format all accumulated sources into a single bulleted list\n",
    "    all_sources = \"\\n\".join(source for source in state.sources_gathered)\n",
    "    state.running_summary = f\"## Summary\\n\\n{state.running_summary}\\n\\n ### Sources:\\n{all_sources}\"\n",
    "    return {\"running_summary\": state.running_summary}\n",
    "\n",
    "def translate_summary(state: SummaryState):\n",
    "    \"\"\" Summarize the gathered sources \"\"\"\n",
    "\n",
    "    print(\"Effettuo TRaduzione\")\n",
    "    # Existing summary\n",
    "    existing_summary = state.running_summary\n",
    "\n",
    "    # Build the human message\n",
    "    human_message_content = (\n",
    "        f\"Translate in italian the existing summary: {existing_summary}\\n\\n\"\n",
    "    )\n",
    "\n",
    "    # Run the LLM\n",
    "    result = llm.invoke(\n",
    "        [SystemMessage(content=translator_instructions),\n",
    "        HumanMessage(content=human_message_content)]\n",
    "    )\n",
    "\n",
    "    italian_summary = result.content\n",
    "    print(f\"Sommario in italiano : {italian_summary}\")\n",
    "    return {\"italian_summary\": italian_summary}\n",
    "\n",
    "\n",
    "def route_research(state: SummaryState, config: RunnableConfig) -> Literal[\"finalize_summary\", \"web_research\"]:\n",
    "    \"\"\" Route the research based on the follow-up query \"\"\"\n",
    "\n",
    "    print(\"Route Research\")\n",
    "    configurable = Configuration.from_runnable_config(config)\n",
    "    if state.research_loop_count <= configurable.max_web_research_loops:\n",
    "        return \"web_research\"\n",
    "    else:\n",
    "        return \"finalize_summary\" \n",
    "    \n",
    "# Add nodes and edges \n",
    "builder = StateGraph(SummaryState, input=SummaryStateInput, output=SummaryStateOutput, config_schema=Configuration)\n",
    "builder.add_node(\"generate_query\", generate_query)\n",
    "builder.add_node(\"web_research\", web_research)\n",
    "builder.add_node(\"summarize_sources\", summarize_sources)\n",
    "builder.add_node(\"reflect_on_summary\", reflect_on_summary)\n",
    "builder.add_node(\"finalize_summary\", finalize_summary)\n",
    "builder.add_node(\"translate_summary\", translate_summary)\n",
    "\n",
    "# Add edges\n",
    "builder.add_edge(START, \"generate_query\")\n",
    "builder.add_edge(\"generate_query\", \"web_research\")\n",
    "builder.add_edge(\"web_research\", \"summarize_sources\")\n",
    "builder.add_edge(\"summarize_sources\", \"reflect_on_summary\")\n",
    "builder.add_conditional_edges(\"reflect_on_summary\", route_research)\n",
    "builder.add_edge(\"finalize_summary\", \"translate_summary\")\n",
    "builder.add_edge(\"translate_summary\", END)\n",
    "\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80ba4822-2884-4106-abb0-727da361d8bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph\n",
    "from IPython.display import Image, display\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c197462b-ef02-4415-8a86-382b3d7e96c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "genero la query\n",
      "Query generata : {'query': 'best frameworks for building large language model (LLM) agents', 'aspect': 'development frameworks', 'rationale': 'looking for recommendations on the most suitable frameworks for creating LLM agents'}\n",
      "Effettuo la ricerca\n",
      "Esito ricerca : Sources:\n",
      "\n",
      "Source A Tour of Popular Open Source Frameworks for LLM-Powered Agents:\n",
      "===\n",
      "URL: https://blog.dataiku.com/open-source-frameworks-for-llm-powered-agents\n",
      "===\n",
      "Most relevant content from source: The purpose of this blog post is to present some of the most popular open source Python frameworks used to implement LLM-powered agents. CrewAI and AutoGen are presented asmulti-agent frameworkswhile LlamaIndex focuses onsingle agentsystems, and LangGraph enables both approaches. Distinctive Features of Agent Frameworks Please note that the LlamaIndex team is currently buildingllama-agents, a powerful framework for building production multi-agent AI systems but we do not cover it in this blog post because it is in an early stage. AutoGenis a multi-agent framework developed by Microsoft. CrewAIis a developer-friendly multi-agent framework. As illustrated inthe Dataiku LLM Starter Kit,Dataiku can support the development of agent applicationsthrough various features:\n",
      "===\n",
      "Full source content limited to 1000 tokens: A Tour of Popular Open Source Frameworks for LLM-Powered Agents\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Product\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Discover Dataiku Where everyone can create and consume AI\n",
      "\n",
      "\n",
      "Dataiku Key Capabilities\n",
      "\n",
      "Plugins and Connectors\n",
      "\n",
      "Plans and Editions\n",
      "        *   *   A Single Platform For\n",
      "\n",
      "\n",
      "Data Preparation\n",
      "\n",
      "Visualization\n",
      "Machine Learning\n",
      "DataOps\n",
      "MLOps\n",
      "\n",
      "Analytic Apps\n",
      "        *   *   Designed for Scale\n",
      "\n",
      "\n",
      "Collaboration\n",
      "\n",
      "Governance\n",
      "Explainability\n",
      "Architecture\n",
      "Security\n",
      "Extensibility\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Explore Dataiku Capabilities for Generative AI Dataiku for Gen AI\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Solutions\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataiku For Your Industry\n",
      "\n",
      "\n",
      "Banking\n",
      "\n",
      "Pharmaceuticals\n",
      "Manufacturing\n",
      "Telecommunications\n",
      "Insurance\n",
      "Retail & CPG\n",
      "Public Sector\n",
      "Utilities & Energy\n",
      "Health Care\n",
      "\n",
      "Media & Entertainment\n",
      "        *   *   Dataiku For Your Department\n",
      "\n",
      "\n",
      "Marketing\n",
      "\n",
      "Logistics & Supply Chain\n",
      "\n",
      "Finance & Audit\n",
      "        *   *   Dataiku For Your Role\n",
      "\n",
      "\n",
      "Tech Experts\n",
      "\n",
      "Business Experts\n",
      "Enterprise Leaders\n",
      "Dataiku Solutions Catalog\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " Jumpstart AI Efforts With Seven Use Cases Built for Retailers RETAIL ACCELERATOR PACK\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Stories\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Dataiku Customer Stories See Everyday AI in action\n",
      "\n",
      "\n",
      "Web Series\n",
      "\n",
      "\n",
      "AI and Us\n",
      "\n",
      "Proof of Concept\n",
      "EGG on Air\n",
      "ML Research, In Practice\n",
      "\n",
      "Dataiku Product Days\n",
      "        *   *   Dataiku Experiences\n",
      "\n",
      "\n",
      "History of Data Science\n",
      "\n",
      "AI Maturity Survey\n",
      "Data Science Pioneers Documentary\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " See how Vestas will reduce express shipment costs by 11-36% DISCOVER THE STORY\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Company\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Join Dataiku We're hiring, join the adventure\n",
      "\n",
      "\n",
      "Engineering at Dataiku\n",
      "        *   *   About Dataiku\n",
      "\n",
      "Customers\n",
      "Events\n",
      "Dataiku for the Future\n",
      "Press Releases\n",
      "Media Kit\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " AI Is Changing Our Everyday Lives. For Good? WATCH THE NEW WEB SERIES AI & US\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Partners\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Find a Dataiku Partner Work with our expert Partners\n",
      "\n",
      "\n",
      "Service Partners\n",
      "\n",
      "Technology Partners\n",
      "\n",
      "Become a Dataiku Partner\n",
      "        *   *   Cloud Providers\n",
      "\n",
      "\n",
      "AWS\n",
      "\n",
      "Snowflake\n",
      "Microsoft\n",
      "Google Cloud\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " 3x Partner of the Year: Snowflake, Databricks, & AWS SEE WHAT'S IN STORE FOR 2024\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Blog\n",
      "\n",
      "GET STARTED\n",
      "CONTACT US\n",
      "Contact us Get Started\n",
      "\n",
      "A Tour of Popular Open Source Frameworks for LLM-Powered Agents\n",
      "October 2, 2024\n",
      "Use Cases & Projects, Featured, Tech Blog Loic Vanel Tabueu Tagne\n",
      "One of the most interesting Generative AI trends is the development of agents powered by large language models (LLMs). The word agent denotes an automated system that can perceive its environment and take actions. More specifically, in the context of LLMs, as explained in a recentacademic article entitled AI Agents That Matter,this word is used mainly when one or several of the following conditions are met:\n",
      "\n",
      "The surrounding environment is complex and the potential tasks are open ended.\n",
      "The system can be given directives in natural language.\n",
      "The system can act with limited or no supervision from a human user.\n",
      "The system can use external tools.\n",
      "The control flow of the system is dynamic.\n",
      "\n",
      "The purpose of this blog post is to present some of the most popular open source Python frameworks used to implement LLM-powered agents. We will focus on the following frameworks and we will highlight their similarities as well as their differences (and summarize them in a table in the appendix):\n",
      "\n",
      "LangGraph: A general, low-level library of the LangChain ecosystem\n",
      "LlamaIndex: A framework specialized in the implementation of retrieval-augmented LLM pipelines\n",
      "AutoGen: A framework that models an LLM application as a conversation between multiple agents\n",
      "CrewAI: A multi-agent framework that emphasizes user-friendliness\n",
      "\n",
      "Features Common to All Frameworks\n",
      "Lets start with the similarities between these frameworks. First, they all offer the possibility toimplement one or several predefined execution logics. The execution logic defines the sequence of LLM completion queries, tool invocations, and user interactions that allows an agent to complete its task.ReActis a popular example of agent execution logic. All frameworks above also allow developers to create customized execution logics.\n",
      "... [truncated]\n",
      "Effettuo sommario\n",
      "Sommario : Here is a summary of the search results:\n",
      "\n",
      "The article discusses the development of LLM-powered agents and presents several popular open-source Python frameworks for implementing these agents. The frameworks highlighted are LangGraph, LlamaIndex, AutoGen, and CrewAI.\n",
      "\n",
      "LangGraph is a general library that provides a low-level foundation for building LLM-powered agents. LlamaIndex is a framework specialized in retrieval-augmented LLM pipelines. AutoGen models an LLM application as a conversation between multiple agents, while CrewAI is a multi-agent framework that emphasizes user-friendliness.\n",
      "\n",
      "All four frameworks offer the possibility to implement predefined execution logics and allow developers to create customized ones. The article concludes by highlighting the similarities and differences between these frameworks, providing a table in the appendix for further reference.\n",
      "\n",
      "Key takeaways:\n",
      "\n",
      "* LangGraph provides a general foundation for building LLM-powered agents\n",
      "* LlamaIndex specializes in retrieval-augmented LLM pipelines\n",
      "* AutoGen models an LLM application as a conversation between multiple agents\n",
      "* CrewAI is a multi-agent framework that emphasizes user-friendliness\n",
      "Ragiono sul sommario\n",
      "Route Research\n",
      "Effettuo la ricerca\n",
      "Esito ricerca : Sources:\n",
      "\n",
      "Source How to use LangGraph Platform to deploy CrewAI, AutoGen, and other ...:\n",
      "===\n",
      "URL: https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/\n",
      "===\n",
      "Most relevant content from source: [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-1)import getpass [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-2)import os [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-3) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-4) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-6)    if not os.environ.get(var): [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-8) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-9) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-10)_set_env(\"OPENAI_API_KEY\") [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-1)import autogen [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-2)import os [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-3) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-5) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-6)llm_config = { [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-7)    \"timeout\": 600, [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-10)    \"temperature\": 0, [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-11)} [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-12) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-13)autogen_agent = autogen.AssistantAgent( [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-14)    name=\"assistant\", [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-16)) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-17) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-19)    name=\"user_proxy\", [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-21)    max_consecutive_auto_reply=10, [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-23)    code_execution_config={ [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-24)        \"work_dir\": \"web\", [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-25)        \"use_docker\": False, [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-26)    },  # Please set use_docker=True if docker is available to run the generated code. [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-28)    system_message=\"Reply TERMINATE if the task has been solved at full satisfaction. [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-29)) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-1)from langgraph.graph import StateGraph, MessagesState [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-2) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-3) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-4)def call_autogen_agent(state: MessagesState): [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-6)    response = user_proxy.initiate_chat(autogen_agent, message=last_message.content) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-7)    # get the final response from the agent [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-8)    content = response.chat_history[-1][\"content\"] [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-9)    return {\"messages\": {\"role\": \"assistant\", \"content\": content}} [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-10) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-11) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-12)graph = StateGraph(MessagesState) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-13)graph.add_node(call_autogen_agent) [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-14)graph.set_entry_point(\"call_autogen_agent\") [](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-3-15)graph = graph.compile()\n",
      "===\n",
      "Full source content limited to 1000 tokens: How to use LangGraph Platform to deploy CrewAI, AutoGen, and other frameworks\n",
      "Skip to content\n",
      " \n",
      "How to use LangGraph Platform to deploy CrewAI, AutoGen, and other frameworks\n",
      "\n",
      "Initializing search\n",
      "GitHub\n",
      "\n",
      "Home\n",
      "Tutorials\n",
      "How-to Guides\n",
      "Conceptual Guides\n",
      "Reference\n",
      "\n",
      " \n",
      "GitHub\n",
      "\n",
      "Home\n",
      "Tutorials\n",
      "How-to Guides\n",
      "Conceptual Guides\n",
      "Reference\n",
      "\n",
      "Table of contents\n",
      "\n",
      "Setup\n",
      "Define autogen agent\n",
      "Wrap in LangGraph\n",
      "Deploy with LangGraph Platform\n",
      "\n",
      "How to use LangGraph Platform to deploy CrewAI, AutoGen, and other frameworks\n",
      "LangGraph Platform provides infrastructure for deploying agents. This integrates seamlessly with LangGraph, but can also work with other frameworks. The way to make this work is to wrap the agent in a single LangGraph node, and have that be the entire graph.\n",
      "Doing so will allow you to deploy to LangGraph Platform, and allows you to get a lot of the benefits. You get horizontally scalable infrastructure, a task queue to handle bursty operations, a persistence layer to power short term memory, and long term memory support.\n",
      "In this guide we show how to do this with an AutoGen agent, but this method should work for agents defined in other frameworks like CrewAI, LlamaIndex, and others as well.\n",
      "Setup\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-0-1)%pip install autogen langgraph\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-1)import getpass\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-2)import os\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-3)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-4)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-5)def _set_env(var: str):\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-6)    if not os.environ.get(var):\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-7)        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-8)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-9)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-1-10)_set_env(\"OPENAI_API_KEY\")\n",
      "Define autogen agent\n",
      "Here we define our AutoGen agent. From https://github.com/microsoft/autogen/blob/0.2/notebook/agentchat_web_info.ipynb\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-1)import autogen\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-2)import os\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-3)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-4)config_list = [{\"model\": \"gpt-4o\", \"api_key\": os.environ[\"OPENAI_API_KEY\"]}]\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-5)\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-6)llm_config = {\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-7)    \"timeout\": 600,\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-8)    \"cache_seed\": 42,\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-9)    \"config_list\": config_list,\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-10)    \"temperature\": 0,\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-11)}\n",
      "[](https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/#__codelineno-2-12)... [truncated]\n",
      "Effettuo sommario\n",
      "Sommario : Here is a continuation of the guide on how to wrap an AutoGen agent in a single LangGraph node:\n",
      "\n",
      "Define autogen agent (continued)\n",
      "```python\n",
      "def create_agent():\n",
      "    return autogen.Agent(\n",
      "        name=\"AutoGen Agent\",\n",
      "        config=llm_config,\n",
      "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
      "        timeout=600,\n",
      "        cache_seed=42,\n",
      "    )\n",
      "```\n",
      "This defines a function `create_agent` that returns an instance of the AutoGen agent with the specified configuration.\n",
      "\n",
      "Wrap the agent in a LangGraph node\n",
      "```python\n",
      "import langgraph\n",
      "\n",
      "def create_graph():\n",
      "    graph = langgraph.Graph()\n",
      "    graph.add_node(create_agent())\n",
      "    return graph\n",
      "```\n",
      "This defines a function `create_graph` that creates a new LangGraph instance and adds the AutoGen agent as a single node to it.\n",
      "\n",
      "Deploy the graph to LangGraph Platform\n",
      "```python\n",
      "import os\n",
      "\n",
      "def deploy_graph(graph):\n",
      "    # Set up LangGraph Platform credentials\n",
      "    api_key = os.environ[\"LANGGRAPH_API_KEY\"]\n",
      "    endpoint = \"https://api.langgraph.com/v1/graphs\"\n",
      "\n",
      "    # Create a new graph deployment\n",
      "    deployment = {\n",
      "        \"name\": \"AutoGen Agent Graph\",\n",
      "        \"graph_id\": graph.id,\n",
      "        \"config\": {\n",
      "            \"timeout\": 600,\n",
      "            \"cache_seed\": 42,\n",
      "        },\n",
      "    }\n",
      "\n",
      "    # Deploy the graph to LangGraph Platform\n",
      "    response = requests.post(endpoint, json=deployment)\n",
      "    if response.status_code == 201:\n",
      "        print(\"Graph deployed successfully!\")\n",
      "    else:\n",
      "        print(\"Error deploying graph:\", response.text)\n",
      "\n",
      "# Create and deploy the graph\n",
      "graph = create_graph()\n",
      "deploy_graph(graph)\n",
      "```\n",
      "This defines a function `deploy_graph` that takes the LangGraph instance as input and deploys it to LangGraph Platform. It sets up credentials, creates a new graph deployment, and sends a POST request to deploy the graph.\n",
      "\n",
      "Run the code\n",
      "```bash\n",
      "python autogen_langgraph_example.py\n",
      "```\n",
      "This will create an AutoGen agent, wrap it in a LangGraph node, and deploy it to LangGraph Platform.\n",
      "\n",
      "Note: This is just an example guide, and you may need to modify the code to fit your specific use case. Additionally, make sure to replace the placeholders (e.g., `OPENAI_API_KEY`, `LANGGRAPH_API_KEY`) with actual values for your environment.\n",
      "Ragiono sul sommario\n",
      "Route Research\n",
      "Effettuo la ricerca\n",
      "Esito ricerca : Sources:\n",
      "\n",
      "Source Handling Tool Calling Errors in LangGraph: A Guide with Examples:\n",
      "===\n",
      "URL: https://medium.com/@gopiariv/handling-tool-calling-errors-in-langgraph-a-guide-with-examples-f391b7acb15e\n",
      "===\n",
      "Most relevant content from source: Handling Tool Calling Errors in LangGraph: A Guide with Examples | by Gopi Arivalagan | Dec, 2024 | Medium Handling Tool Calling Errors in LangGraph: A Guide with Examples This blog post covers strategies and examples for effectively handling tool calling errors in LangGraph. Why Tool Calling Errors Occur While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential. The ToolNode in LangGraph automatically captures tool errors and reports them to the model. If youre new to Medium, create a new account to read this story on us. LangGraph: A Beginners Guide to Building AI Workflows ------------------------------------------------------ ### Are you interested in creating AI applications that can handle complex tasks? Towards AI\n",
      "===\n",
      "Full source content limited to 1000 tokens: Handling Tool Calling Errors in LangGraph: A Guide with Examples | by Gopi Arivalagan | Dec, 2024 | Medium\n",
      "Open in app\n",
      "Sign up\n",
      "Sign in\n",
      "\n",
      "Write\n",
      "\n",
      "Sign up\n",
      "Sign in\n",
      "\n",
      "Member-only story\n",
      "Handling Tool Calling Errors in LangGraph: A Guide with Examples\n",
      "\n",
      "Gopi Arivalagan\n",
      "Follow\n",
      "2 min read\n",
      "\n",
      "Dec 7, 2024\n",
      "\n",
      "\n",
      "Listen\n",
      "Share\n",
      "LangGraph provides a robust framework for creating agents capable of iterative reasoning and action, commonly implemented as ReAct agents. However, tool calling  a critical aspect of these agents  can encounter issues due to tool misuse by the LLM or misaligned input expectations. This blog post covers strategies and examples for effectively handling tool calling errors in LangGraph.\n",
      "Why Tool Calling Errors Occur\n",
      "LLMs might:\n",
      "\n",
      "Call Nonexistent Tools: Errors due to typos or ambiguous tool names.\n",
      "Misuse Arguments: Pass arguments that do not adhere to the expected schema.\n",
      "Lack Context: Provide inputs inconsistent with prior agent states.\n",
      "\n",
      "While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential.\n",
      "Built-in Error Handling with ToolNode\n",
      "The ToolNode in LangGraph automatically captures tool errors and reports them to the model. Here's an example setup:\n",
      "from langchain_core.tools import tool\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph.graph import StateGraph, MessagesState\n",
      "from langgraph.prebuilt import ToolNode\n",
      "@tool\n",
      "def get_weather(location: str):\n",
      "    \"\"\"Call to get the current weather.\"\"\"\n",
      "    if location.lower() == \"san francisco\"\n",
      "Create an account to readthefullstory.\n",
      "\n",
      "Theauthor made this story available toMediummembersonly.\n",
      "If youre new to Medium, create a new account to read this story on us.\n",
      "Continue in app\n",
      "Or, continue in mobile web\n",
      "Sign up with Google\n",
      "Sign up with Facebook\n",
      "Sign up with email\n",
      "Already have an account? Sign in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Follow\n",
      "Written by Gopi Arivalagan --------------------------\n",
      "6 Followers\n",
      "23 Following\n",
      "Follow\n",
      "No responses yet\n",
      "\n",
      "What are your thoughts?\n",
      "Cancel\n",
      "Respond\n",
      "Respond\n",
      "Also publish to my profile\n",
      "More from Gopi Arivalagan\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "LangGraph: A Beginners Guide to Building AI Workflows ------------------------------------------------------ ### Are you interested in creating AI applications that can handle complex tasks? Meet LangGraph, a powerful yet beginner-friendly framework\n",
      "Jul 31\n",
      "12\n",
      "\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "Learning from a game -------------------- ### I downloaded a game called qubes in my tablet. I started playing and got a max score of 80 after 30 tries. One day my friend (a lazy\n",
      "Jan 1, 2016\n",
      "24\n",
      "\n",
      "See all from Gopi Arivalagan\n",
      "Recommended from Medium\n",
      "\n",
      "\n",
      "In\n",
      "AI Advances\n",
      "by\n",
      "Debmalya Biswas\n",
      "Long-term Memory for AI Agents ------------------------------ ### Why Vector Databases are not sufficient for Memory Management of Agentic AI Systems?\n",
      "5d ago\n",
      "921 17\n",
      "\n",
      "\n",
      "\n",
      "In\n",
      "Generative AI\n",
      "by\n",
      "Satyabrata Dash\n",
      "Understanding Graph-based RAG Systems: A Deep Dive into GraphRAG and LightRAG ----------------------------------------------------------------------------- ### The Need for Graph-based RAG Systems\n",
      "6d ago\n",
      "151\n",
      "\n",
      "Lists\n",
      "   Staff picks ----------- 788 stories1499 saves\n",
      "   Stories to Help You Level-Up at Work ------------------------------------ 19 stories892 saves\n",
      "   Self-Improvement 101 -------------------- 20 stories3132 saves\n",
      "   Productivity 101 ---------------- 20 stories2648 saves\n",
      "\n",
      "\n",
      "In\n",
      "Towards AI\n",
      "by\n",
      "Tarun Singh\n",
      "Mastering Data Extraction with LlamaExtract: JSON Outputs from PDFs, Payslips, and More --------------------------------------------------------------------------------------- ### 1. Introduction\n",
      "5d ago\n",
      "66 1\n",
      "\n",
      "\n",
      "\n",
      "Ignacio de Gregorio\n",
      "Why Amazons AI Strategy is Finally Legit. ------------------------------------------ ### Finally, this week, Amazon officially became a strong player in the frontier AI scene, all the while making the lives of those trying to\n",
      "4d ago\n",
      "973 25\n",
      "\n",
      "\n",
      "\n",
      "Samar Singh\n",
      "Pydantic AI: The Python Agent Framework to BUILD Production-Grade AI Agents! ---------------------------------------... [truncated]\n",
      "Effettuo sommario\n",
      "Sommario : Here is a continuation of the guide on how to wrap an AutoGen agent in a single LangGraph node:\n",
      "\n",
      "Defining autogen agent (continued)\n",
      "```python\n",
      "def create_agent():\n",
      "    return autogen.Agent(\n",
      "        name=\"AutoGen Agent\",\n",
      "        config=llm_config,\n",
      "        api_key=os.environ[\"OPENAI_API_KEY\"],\n",
      "        timeout=600,\n",
      "        cache_seed=42,\n",
      "    )\n",
      "```\n",
      "This defines a function `create_agent` that returns an instance of the AutoGen agent with the specified configuration.\n",
      "\n",
      "Wrap the agent in a LangGraph node\n",
      "```python\n",
      "import langgraph\n",
      "\n",
      "def create_graph():\n",
      "    graph = langgraph.Graph()\n",
      "    graph.add_node(create_agent())\n",
      "    return graph\n",
      "```\n",
      "This defines a function `create_graph` that creates a new LangGraph instance and adds the AutoGen agent as a single node to it.\n",
      "\n",
      "Deploying the graph to LangGraph Platform (continued)\n",
      "```python\n",
      "import os\n",
      "\n",
      "def deploy_graph(graph):\n",
      "    # Set up LangGraph Platform credentials\n",
      "    api_key = os.environ[\"LANGGRAPH_API_KEY\"]\n",
      "    endpoint = \"https://api.langgraph.com\"\n",
      "\n",
      "    # Create a new ToolNode with error handling\n",
      "    tool_node = ToolNode(\n",
      "        name=\"AutoGen Agent\",\n",
      "        tool=get_weather,\n",
      "        args=[\"San Francisco\"],\n",
      "        context={\"location\": \"San Francisco\"},\n",
      "        error_handler=lambda e: print(f\"Error occurred: {e}\")\n",
      "    )\n",
      "\n",
      "    # Add the ToolNode to the graph\n",
      "    graph.add_node(tool_node)\n",
      "\n",
      "    # Deploy the graph to LangGraph Platform\n",
      "    response = requests.post(endpoint + \"/graph\", json=graph.to_dict())\n",
      "    if response.status_code == 200:\n",
      "        print(\"Graph deployed successfully\")\n",
      "    else:\n",
      "        print(\"Error deploying graph:\", response.text)\n",
      "```\n",
      "This defines a function `deploy_graph` that creates a new ToolNode with error handling and adds it to the graph. It then deploys the graph to LangGraph Platform using the `requests` library.\n",
      "\n",
      "Built-in Error Handling\n",
      "The ToolNode in LangGraph automatically captures tool errors and reports them to the model. This is demonstrated in the example code above, where we define a custom error handler function that prints any errors that occur during execution.\n",
      "\n",
      "Why Tool Calling Errors Occur\n",
      "Tool calling errors can occur due to various reasons, including:\n",
      "\n",
      "* Typos or ambiguous tool names\n",
      "* Misuse of arguments that do not adhere to the expected schema\n",
      "* Lack of context, such as providing inputs inconsistent with prior agent states\n",
      "\n",
      "To mitigate these errors, it is essential to improve tool schemas, descriptions, and limiting tool options. Additionally, robust error handling strategies are necessary to handle any errors that may occur during execution.\n",
      "\n",
      "Best Practices for Tool Calling\n",
      "Here are some best practices for tool calling in LangGraph:\n",
      "\n",
      "* Use clear and concise tool names and descriptions\n",
      "* Ensure that arguments adhere to the expected schema\n",
      "* Provide context for inputs, such as prior agent states or environment variables\n",
      "\n",
      "By following these best practices, you can minimize the risk of tool calling errors and ensure that your agents behave predictably and robustly.\n",
      "Ragiono sul sommario\n",
      "Route Research\n",
      "Effettuo la ricerca\n",
      "Esito ricerca : Sources:\n",
      "\n",
      "Source Handling Tool Calling Errors in LangGraph: A Guide with Examples:\n",
      "===\n",
      "URL: https://medium.com/@gopiariv/handling-tool-calling-errors-in-langgraph-a-guide-with-examples-f391b7acb15e\n",
      "===\n",
      "Most relevant content from source: Handling Tool Calling Errors in LangGraph: A Guide with Examples | by Gopi Arivalagan | Dec, 2024 | Medium Handling Tool Calling Errors in LangGraph: A Guide with Examples This blog post covers strategies and examples for effectively handling tool calling errors in LangGraph. Why Tool Calling Errors Occur While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential. The ToolNode in LangGraph automatically captures tool errors and reports them to the model. If youre new to Medium, create a new account to read this story on us. LangGraph: A Beginners Guide to Building AI Workflows ------------------------------------------------------ ### Are you interested in creating AI applications that can handle complex tasks? Towards AI\n",
      "===\n",
      "Full source content limited to 1000 tokens: Handling Tool Calling Errors in LangGraph: A Guide with Examples | by Gopi Arivalagan | Dec, 2024 | Medium\n",
      "Open in app\n",
      "Sign up\n",
      "Sign in\n",
      "\n",
      "Write\n",
      "\n",
      "Sign up\n",
      "Sign in\n",
      "\n",
      "Member-only story\n",
      "Handling Tool Calling Errors in LangGraph: A Guide with Examples\n",
      "\n",
      "Gopi Arivalagan\n",
      "Follow\n",
      "2 min read\n",
      "\n",
      "Dec 7, 2024\n",
      "\n",
      "\n",
      "Listen\n",
      "Share\n",
      "LangGraph provides a robust framework for creating agents capable of iterative reasoning and action, commonly implemented as ReAct agents. However, tool calling  a critical aspect of these agents  can encounter issues due to tool misuse by the LLM or misaligned input expectations. This blog post covers strategies and examples for effectively handling tool calling errors in LangGraph.\n",
      "Why Tool Calling Errors Occur\n",
      "LLMs might:\n",
      "\n",
      "Call Nonexistent Tools: Errors due to typos or ambiguous tool names.\n",
      "Misuse Arguments: Pass arguments that do not adhere to the expected schema.\n",
      "Lack Context: Provide inputs inconsistent with prior agent states.\n",
      "\n",
      "While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential.\n",
      "Built-in Error Handling with ToolNode\n",
      "The ToolNode in LangGraph automatically captures tool errors and reports them to the model. Here's an example setup:\n",
      "from langchain_core.tools import tool\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph.graph import StateGraph, MessagesState\n",
      "from langgraph.prebuilt import ToolNode\n",
      "@tool\n",
      "def get_weather(location: str):\n",
      "    \"\"\"Call to get the current weather.\"\"\"\n",
      "    if location.lower() == \"san francisco\"\n",
      "Create an account to readthefullstory.\n",
      "\n",
      "Theauthor made this story available toMediummembersonly.\n",
      "If youre new to Medium, create a new account to read this story on us.\n",
      "Continue in app\n",
      "Or, continue in mobile web\n",
      "Sign up with Google\n",
      "Sign up with Facebook\n",
      "Sign up with email\n",
      "Already have an account? Sign in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Follow\n",
      "Written by Gopi Arivalagan --------------------------\n",
      "6 Followers\n",
      "23 Following\n",
      "Follow\n",
      "No responses yet\n",
      "\n",
      "What are your thoughts?\n",
      "Cancel\n",
      "Respond\n",
      "Respond\n",
      "Also publish to my profile\n",
      "More from Gopi Arivalagan\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "LangGraph: A Beginners Guide to Building AI Workflows ------------------------------------------------------ ### Are you interested in creating AI applications that can handle complex tasks? Meet LangGraph, a powerful yet beginner-friendly framework\n",
      "Jul 31\n",
      "12\n",
      "\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "Learning from a game -------------------- ### I downloaded a game called qubes in my tablet. I started playing and got a max score of 80 after 30 tries. One day my friend (a lazy\n",
      "Jan 1, 2016\n",
      "24\n",
      "\n",
      "See all from Gopi Arivalagan\n",
      "Recommended from Medium\n",
      "\n",
      "\n",
      "In\n",
      "AI Advances\n",
      "by\n",
      "Debmalya Biswas\n",
      "Long-term Memory for AI Agents ------------------------------ ### Why Vector Databases are not sufficient for Memory Management of Agentic AI Systems?\n",
      "5d ago\n",
      "921 17\n",
      "\n",
      "\n",
      "\n",
      "In\n",
      "Generative AI\n",
      "by\n",
      "Satyabrata Dash\n",
      "Understanding Graph-based RAG Systems: A Deep Dive into GraphRAG and LightRAG ----------------------------------------------------------------------------- ### The Need for Graph-based RAG Systems\n",
      "6d ago\n",
      "151\n",
      "\n",
      "Lists\n",
      "   Staff picks ----------- 788 stories1499 saves\n",
      "   Stories to Help You Level-Up at Work ------------------------------------ 19 stories892 saves\n",
      "   Self-Improvement 101 -------------------- 20 stories3132 saves\n",
      "   Productivity 101 ---------------- 20 stories2648 saves\n",
      "\n",
      "\n",
      "In\n",
      "Towards AI\n",
      "by\n",
      "Tarun Singh\n",
      "Mastering Data Extraction with LlamaExtract: JSON Outputs from PDFs, Payslips, and More --------------------------------------------------------------------------------------- ### 1. Introduction\n",
      "5d ago\n",
      "66 1\n",
      "\n",
      "\n",
      "\n",
      "Ignacio de Gregorio\n",
      "Why Amazons AI Strategy is Finally Legit. ------------------------------------------ ### Finally, this week, Amazon officially became a strong player in the frontier AI scene, all the while making the lives of those trying to\n",
      "4d ago\n",
      "973 25\n",
      "\n",
      "\n",
      "\n",
      "Samar Singh\n",
      "Pydantic AI: The Python Agent Framework to BUILD Production-Grade AI Agents! ---------------------------------------... [truncated]\n",
      "Effettuo sommario\n",
      "Sommario : Here is a continuation of the existing summary:\n",
      "\n",
      "Wrapping an AutoGen agent in a LangGraph node\n",
      "The previous section provided an overview of how to define and wrap an AutoGen agent within a single LangGraph node. This process involves creating a function `create_agent` that returns an instance of the AutoGen agent with specified configuration, and another function `create_node` that wraps this agent within a LangGraph node.\n",
      "\n",
      "Handling Tool Calling Errors in LangGraph\n",
      "Tool calling is a critical aspect of ReAct agents implemented using LangGraph. However, tool calling can encounter issues due to tool misuse by the LLM or misaligned input expectations. This section covers strategies and examples for effectively handling tool calling errors in LangGraph.\n",
      "\n",
      "Built-in Error Handling with ToolNode\n",
      "The ToolNode in LangGraph provides built-in error handling capabilities that capture tool errors and report them to the model. An example setup is provided, which demonstrates how to create a ToolNode using the `ToolNode` class from `langgraph.graph`.\n",
      "\n",
      "Robust Error Handling Strategies\n",
      "While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential. The author suggests that developers should be aware of potential issues with tool calling and take steps to prevent them.\n",
      "\n",
      "Best Practices for Tool Calling\n",
      "To avoid tool calling errors, it is recommended to follow best practices such as:\n",
      "\n",
      "* Ensuring that tools are properly registered and configured\n",
      "* Validating input arguments to prevent misuse\n",
      "* Providing context and information about the tool call\n",
      "* Implementing robust error handling mechanisms\n",
      "\n",
      "By following these strategies and best practices, developers can build more reliable and robust LangGraph agents that can handle complex tasks effectively.\n",
      "\n",
      "Full source content limited to 1000 tokens:\n",
      "\n",
      "Handling Tool Calling Errors in LangGraph: A Guide with Examples | by Gopi Arivalagan | Dec 7, 2024 | Medium\n",
      "\n",
      "Sign up\n",
      "Sign in\n",
      "\n",
      "Member-only story\n",
      "Handling Tool Calling Errors in LangGraph: A Guide with Examples\n",
      "\n",
      "Gopi Arivalagan\n",
      "Follow\n",
      "2 min read\n",
      "\n",
      "Dec 7, 2024\n",
      "\n",
      "\n",
      "Listen\n",
      "Share\n",
      "LangGraph provides a robust framework for creating agents capable of iterative reasoning and action, commonly implemented as ReAct agents. However, tool calling  a critical aspect of these agents  can encounter issues due to tool misuse by the LLM or misaligned input expectations. This blog post covers strategies and examples for effectively handling tool calling errors in LangGraph.\n",
      "\n",
      "Why Tool Calling Errors Occur\n",
      "LLMs might:\n",
      "\n",
      "Call Nonexistent Tools: Errors due to typos or ambiguous tool names.\n",
      "Misuse Arguments: Pass arguments that do not adhere to the expected schema.\n",
      "Lack Context: Provide inputs inconsistent with prior agent states.\n",
      "\n",
      "While improving tool schemas, descriptions, and limiting tool options can mitigate some of these errors, robust error handling strategies are essential.\n",
      "\n",
      "Built-in Error Handling with ToolNode\n",
      "The ToolNode in LangGraph automatically captures tool errors and reports them to the model. Here's an example setup:\n",
      "from langchain_core.tools import tool\n",
      "from langchain_openai import ChatOpenAI\n",
      "from langgraph.graph import StateGraph, MessagesState\n",
      "from langgraph.prebuilt import ToolNode\n",
      "\n",
      "@tool\n",
      "def get_weather(location: str):\n",
      "    \"\"\"Call to get the current weather.\"\"\"\n",
      "    if location.lower() == \"san francisco\"\n",
      "Create an account to readthefullstory.\n",
      "\n",
      "Theauthor made this story available toMediummembersonly.\n",
      "If youre new to Medium, create a new account to read this story on us.\n",
      "Continue in app\n",
      "Or, continue in mobile web\n",
      "Sign up with Google\n",
      "Sign up with Facebook\n",
      "Sign up with email\n",
      "Already have an account? Sign in\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Follow\n",
      "Written by Gopi Arivalagan --------------------------\n",
      "6 Followers\n",
      "23 Following\n",
      "Follow\n",
      "No responses yet\n",
      "\n",
      "What are your thoughts?\n",
      "Cancel\n",
      "Respond\n",
      "Respond\n",
      "Also publish to my profile\n",
      "More from Gopi Arivalagan\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "LangGraph: A Beginners Guide to Building AI Workflows ------------------------------------------------------ ### Are you interested in creating AI applications that can handle complex tasks? Meet LangGraph, a powerful yet beginner-friendly framework\n",
      "Jul 31\n",
      "12\n",
      "\n",
      "\n",
      "\n",
      "Gopi Arivalagan\n",
      "Learning from a game -------------------- ### I downloaded a game called qubes in my tablet. I started playing and got a max score of 80 after 30 tries. One day my friend (a lazy\n",
      "Jan 1, 2016\n",
      "24\n",
      "\n",
      "See all from Gopi Arivalagan\n",
      "Recommended from Medium\n",
      "\n",
      "\n",
      "In\n",
      "AI Advances\n",
      "by\n",
      "Debmalya Biswas\n",
      "Long-term Memory for AI Agents ------------------------------ ### Why Vector Databases are not sufficient for Memory Management of Agentic AI Systems?\n",
      "5d ago\n",
      "921 17\n",
      "\n",
      "\n",
      "\n",
      "In\n",
      "Generative AI\n",
      "by\n",
      "Satyabrata Dash\n",
      "Understanding Graph-based RAG Systems: A Deep Dive into GraphRAG and LightRAG ----------------------------------------------------------------------------- ### The Need for Graph-based RAG Systems\n",
      "6d ago\n",
      "151\n",
      "\n",
      "Lists\n",
      "   Staff picks ----------- 788 stories1499 saves\n",
      "   Stories to Help You Level-Up at Work ------------------------------------ 19 stories892 saves\n",
      "   Self-Improvement 101 -------------------- 20 stories3132 saves\n",
      "   Productivity 101 ---------------- 20 stories2648 saves\n",
      "\n",
      "\n",
      "In\n",
      "Towards AI\n",
      "by\n",
      "Tarun Kumar\n",
      "Building a Robust LangGraph Agent: A Step-by-Step Guide\n",
      "Tarun Kumar\n",
      "Follow\n",
      "1 min read\n",
      "\n",
      "Dec 10, 2024\n",
      "\n",
      "\n",
      "Listen\n",
      "Share\n",
      "Ragiono sul sommario\n",
      "Route Research\n",
      "Finalizzo il sommario\n",
      "Effettuo TRaduzione\n",
      "Sommario in italiano : Ecco la traduzione dell'articolo in italiano:\n",
      "\n",
      "## Riepilogo\n",
      "\n",
      "Ecco una continuazione del riassunto precedente.\n",
      "\n",
      "Avvolgere un agente AutoGen in un nodo LangGraph\n",
      "La sezione precedente ha fornito un' panoramica su come definire e avvolgere un agente AutoGen all'interno di un solo nodo LangGraph. Questo processo implica la creazione di una funzione `create_agent` che restituisce un'istanza dell'agente AutoGen con una configurazione specifica, e un'altra funzione `create_node` che avvolge questo agente all'interno di un nodo LangGraph.\n",
      "\n",
      "Gestione degli errori di chiamata strumentale in LangGraph\n",
      "La chiamata strumentale  un aspetto critico degli agenti ReAct implementati con LangGraph. Tuttavia, la chiamata strumentale pu incontrare problemi a causa dell'errore strumentale da parte del LLM o di aspettative di input non allineate. Questa sezione copre strategie e esempi per gestire efficacemente gli errori di chiamata strumentale in LangGraph.\n",
      "\n",
      "Gestione degli errori interni con ToolNode\n",
      "Il ToolNode in LangGraph fornisce capacit di gestione degli errori interni che catturano gli errori strumentali e li segnalano al modello. Un esempio di configurazione  fornito, che dimostra come creare un ToolNode utilizzando la classe `ToolNode` da `langgraph.graph`.\n",
      "\n",
      "Strategie di gestione degli errori robuste\n",
      "Sebbene migliorare le schematizzazioni strumentali, le descrizioni e limitare le opzioni strumentali possano mitigare alcuni di questi errori, sono essenziali strategie di gestione degli errori robuste. L'autore consiglia ai sviluppatori di essere consapevoli delle potenziali questioni con la chiamata strumentale e prendere misure per prevenirla.\n",
      "\n",
      "Pratiche migliori per la chiamata strumentale\n",
      "Per evitare gli errori di chiamata strumentale,  raccomandato seguire le pratiche migliori come:\n",
      "\n",
      "* Assicurarsi che gli strumenti siano correttamente registrati e configurati\n",
      "* Validare gli argomenti di input per prevenire l'errore\n",
      "* Fornire contesto e informazioni sulla chiamata strumentale\n",
      "* Implementare meccanismi di gestione degli errori robusti\n",
      "\n",
      "Seguendo queste strategie e pratiche migliori, i sviluppatori possono costruire agenti LangGraph pi affidabili e robusti che possano gestire compiti complessi in modo efficace.\n",
      "\n",
      "Contenuto completo limitato a 1000 token:\n",
      "\n",
      "Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan | 7 dicembre 2024 | Medium\n",
      "\n",
      "Iscriviti\n",
      "Accedi\n",
      "\n",
      "Storia riservata per gli utenti\n",
      "Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\n",
      "Segui\n",
      "* Una panoramica dei framework aperti pi popolari per gli agenti LLM : https://blog.dataiku.com/open-source-frameworks-for-llm-powered-agents\n",
      "* Come utilizzare la piattaforma LangGraph per deploy CrewAI, AutoGen e altri ... : https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/\n",
      "* Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\n",
      "* Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\n",
      "\n",
      "Nota: ho mantenuto la struttura e il contenuto originale dell'articolo, ma ho tradotto le parole e i frasi per adattarli all'italiano.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'italian_summary': \"Ecco la traduzione dell'articolo in italiano:\\n\\n## Riepilogo\\n\\nEcco una continuazione del riassunto precedente.\\n\\nAvvolgere un agente AutoGen in un nodo LangGraph\\nLa sezione precedente ha fornito un' panoramica su come definire e avvolgere un agente AutoGen all'interno di un solo nodo LangGraph. Questo processo implica la creazione di una funzione `create_agent` che restituisce un'istanza dell'agente AutoGen con una configurazione specifica, e un'altra funzione `create_node` che avvolge questo agente all'interno di un nodo LangGraph.\\n\\nGestione degli errori di chiamata strumentale in LangGraph\\nLa chiamata strumentale  un aspetto critico degli agenti ReAct implementati con LangGraph. Tuttavia, la chiamata strumentale pu incontrare problemi a causa dell'errore strumentale da parte del LLM o di aspettative di input non allineate. Questa sezione copre strategie e esempi per gestire efficacemente gli errori di chiamata strumentale in LangGraph.\\n\\nGestione degli errori interni con ToolNode\\nIl ToolNode in LangGraph fornisce capacit di gestione degli errori interni che catturano gli errori strumentali e li segnalano al modello. Un esempio di configurazione  fornito, che dimostra come creare un ToolNode utilizzando la classe `ToolNode` da `langgraph.graph`.\\n\\nStrategie di gestione degli errori robuste\\nSebbene migliorare le schematizzazioni strumentali, le descrizioni e limitare le opzioni strumentali possano mitigare alcuni di questi errori, sono essenziali strategie di gestione degli errori robuste. L'autore consiglia ai sviluppatori di essere consapevoli delle potenziali questioni con la chiamata strumentale e prendere misure per prevenirla.\\n\\nPratiche migliori per la chiamata strumentale\\nPer evitare gli errori di chiamata strumentale,  raccomandato seguire le pratiche migliori come:\\n\\n* Assicurarsi che gli strumenti siano correttamente registrati e configurati\\n* Validare gli argomenti di input per prevenire l'errore\\n* Fornire contesto e informazioni sulla chiamata strumentale\\n* Implementare meccanismi di gestione degli errori robusti\\n\\nSeguendo queste strategie e pratiche migliori, i sviluppatori possono costruire agenti LangGraph pi affidabili e robusti che possano gestire compiti complessi in modo efficace.\\n\\nContenuto completo limitato a 1000 token:\\n\\nGestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan | 7 dicembre 2024 | Medium\\n\\nIscriviti\\nAccedi\\n\\nStoria riservata per gli utenti\\nGestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\\nSegui\\n* Una panoramica dei framework aperti pi popolari per gli agenti LLM : https://blog.dataiku.com/open-source-frameworks-for-llm-powered-agents\\n* Come utilizzare la piattaforma LangGraph per deploy CrewAI, AutoGen e altri ... : https://langchain-ai.github.io/langgraph/how-tos/autogen-langgraph-platform/\\n* Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\\n* Gestione degli errori di chiamata strumentale in LangGraph: una guida con esempi | da Gopi Arivalagan\\n\\nNota: ho mantenuto la struttura e il contenuto originale dell'articolo, ma ho tradotto le parole e i frasi per adattarli all'italiano.\"}"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_topic =\"what are the best framework to build llm agents?\"\n",
    "report=graph.invoke({\"research_topic\":report_topic,\n",
    "                           \"Configuration\": Configuration.from_runnable_config()})\n",
    "report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90ebc94f-8a53-48fc-b3b3-8379e36d888c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langchain_env",
   "language": "python",
   "name": "langchain_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
