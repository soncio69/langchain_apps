{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f0174f93",
   "metadata": {},
   "source": [
    "Questo notebook è tratto dalla documentazione ufficiale di langchain 0.3 e ripercorre quanto già visto nel notebook Ollama_tool_calling_001, utilizzando funzioni di calcolo.<br>\n",
    "\n",
    "Utilizza il modello open source llama3.2-3B per dimostrare l'utilizzo di tool calling.\n",
    "\n",
    "Attraverso tool calling un chatmodel può rispondere ad un prompt effettuando una chiamata ad un tool esterno.\n",
    "Tool calling is a general technique that generates structured output from a model, and you can use it even when you don't intend to invoke any tools. \n",
    "\n",
    "I modelli che supportano tool calling sono in grado di generare risposte nel formato previsto da uno schema che viene fornito dall'utente.\n",
    "A fronte di tale risposta è possibile eseguire un tool esterno (in questo caso una funzione) e poi fornire il risultato di questa esecuzione all'llm per avere la risposta finale\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f1500e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "llm = ChatOllama(model=\"llama3.2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3749a05",
   "metadata": {},
   "source": [
    "Perchè un modello possa invocare dei tools è necessario fornire al modello stesso uno schema che descriva:\n",
    "- la funzionalità implementata dal tool\n",
    "- quali sono gli argomenti del tool\n",
    "\n",
    "I Chat Model che supportano tool calling espongono il metodo bind_tools che consente di passare al modello stesso gli schemas dei tools\n",
    "\n",
    "Tool schemas possono essere passati come:\n",
    "- Python functions (with typehints and docstrings),\n",
    "- Pydantic models\n",
    "- TypedDict classes\n",
    "- LangChain Tool objects. \n",
    "\n",
    "Vedi https://python.langchain.com/docs/how_to/tool_calling/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18ca2da9",
   "metadata": {},
   "source": [
    "Definisco 2 funzioni python decorandole con @tool che consente di convertire una funzione in un tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2272ca40",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Adds a and b.\"\"\"\n",
    "    return a + b\n",
    "\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiplies a and b.\"\"\"\n",
    "    return a * b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a67ac08b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'description': 'Adds a and b.',\n",
       " 'properties': {'a': {'title': 'A', 'type': 'integer'},\n",
       "  'b': {'title': 'B', 'type': 'integer'}},\n",
       " 'required': ['a', 'b'],\n",
       " 'title': 'add',\n",
       " 'type': 'object'}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "add.args_schema.model_json_schema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd85477",
   "metadata": {},
   "source": [
    "I 2 tools vengono passati al llm con la funzione bind_tools().\n",
    "\n",
    "E' possibile passare diversi argomento a bind_tools per forzare il modello ad utilizzare un determinato tool o per forzarlo ad usare per forza uno dei tools (llm.bind_tools(tools, tool_choice=\"any\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2b73920",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [add, multiply]\n",
    "\n",
    "llm_with_tools = llm.bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d792494",
   "metadata": {},
   "source": [
    "Dopo che i tools sono stati associati al modello, verranno passati nel prompt nelle successive invocazioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0d47bc7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'multiply', 'args': {'a': '3', 'b': '12'}, 'id': '18da40ec-8dde-4bb7-b63e-9ec8a246d559', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': '11', 'b': '49'}, 'id': '10f0354d-7a75-447b-a91a-8b272e9b75f9', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "query = \"What is 3 * 12? Also, what is 11 + 49?\"\n",
    "\n",
    "# OLtre a HumanMessage sarebbe possibile passare anche SysteMessages\n",
    "#\n",
    "messages = [HumanMessage(query)]\n",
    "\n",
    "# L'invocazione al modello genera gli argomenti che verranno passati successivamente all'invocazione del tool.\n",
    "ai_msg = llm_with_tools.invoke(messages)\n",
    "print(ai_msg.tool_calls)\n",
    "\n",
    "# accodo gli argomenti ai tools ai messaggi\n",
    "messages.append(ai_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42e3270",
   "metadata": {},
   "source": [
    "Per ciascuno dei tool_call presenti nella risposta, effettuo l'invocazione al tool stesso (utilizzando i parametri presenti).\n",
    "\n",
    "Anche le risposte all'invocazione dei tools vengono aggiunti ai messaggi che verranno passati al modello per la risposta finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fe00af6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is 3 * 12? Also, what is 11 + 49?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-23T16:43:17.585891381Z', 'message': {'role': 'assistant', 'content': '', 'tool_calls': [{'function': {'name': 'multiply', 'arguments': {'a': '3', 'b': '12'}}}, {'function': {'name': 'add', 'arguments': {'a': '11', 'b': '49'}}}]}, 'done_reason': 'stop', 'done': True, 'total_duration': 7215876580, 'load_duration': 16881284, 'prompt_eval_count': 231, 'prompt_eval_duration': 3665490000, 'eval_count': 44, 'eval_duration': 3490736000}, id='run-4cd8f228-0c1e-430e-8366-3cd4958151bf-0', tool_calls=[{'name': 'multiply', 'args': {'a': '3', 'b': '12'}, 'id': '18da40ec-8dde-4bb7-b63e-9ec8a246d559', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': '11', 'b': '49'}, 'id': '10f0354d-7a75-447b-a91a-8b272e9b75f9', 'type': 'tool_call'}], usage_metadata={'input_tokens': 231, 'output_tokens': 44, 'total_tokens': 275}),\n",
       " ToolMessage(content='36', name='multiply', tool_call_id='18da40ec-8dde-4bb7-b63e-9ec8a246d559'),\n",
       " ToolMessage(content='60', name='add', tool_call_id='10f0354d-7a75-447b-a91a-8b272e9b75f9')]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\": add, \"multiply\": multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    messages.append(tool_msg)\n",
    "\n",
    "messages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415dd612",
   "metadata": {},
   "source": [
    "Invoco infine il modello passando i messaggi con tutti i dati necessari per produrre la risposta finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa3693c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The result of 3 * 12 is 36.\\n\\nThe result of 11 + 49 is 60.', additional_kwargs={}, response_metadata={'model': 'llama3.2', 'created_at': '2024-10-23T16:45:31.277564206Z', 'message': {'role': 'assistant', 'content': 'The result of 3 * 12 is 36.\\n\\nThe result of 11 + 49 is 60.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2053474106, 'load_duration': 17290948, 'prompt_eval_count': 125, 'prompt_eval_duration': 73036000, 'eval_count': 25, 'eval_duration': 1747772000}, id='run-4b7112ac-54c8-40aa-a784-2c3c00c76ff7-0', usage_metadata={'input_tokens': 125, 'output_tokens': 25, 'total_tokens': 150})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response = llm_with_tools.invoke(messages)\n",
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "63014e2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of 3 * 12 is 36.\n",
      "\n",
      "The result of 11 + 49 is 60.\n"
     ]
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15d1c63",
   "metadata": {},
   "source": [
    "In caso di calcoli più difficili è possibile fornire esempi al modello.\n",
    "\n",
    "Vedi:\n",
    "https://python.langchain.com/docs/how_to/tools_few_shot/\n",
    "\n",
    "VERIFICARE PERCHE' NON FUNZIONA (for"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e2b56e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': '119', 'b': '8'},\n",
       "  'id': '6b5c0601-eeb0-4d6a-841e-8711c4111469',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'subtract',\n",
       "  'args': {'a': 'result of first operation', 'b': '20'},\n",
       "  'id': 'eb9b5669-c869-49ed-9cc7-0944c1d2d4db',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 'result of second operation',\n",
       "   'b': 'result of third operation'},\n",
       "  'id': '0d6b4635-7296-4d58-83f9-2156638a4124',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_with_tools.invoke(\n",
    "    \"Whats 119 times 8 minus 20. Don't do any math yourself, only use tools for math. Respect order of operations\"\n",
    ").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90036231",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'multiply',\n",
       "  'args': {'a': 119, 'b': 8},\n",
       "  'id': 'a31b7a6d-b6e5-4275-9a60-302f312ba638',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'add',\n",
       "  'args': {'a': 7, 'b': -20},\n",
       "  'id': '139d6417-f030-489e-835a-b1e422dc52e0',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import AIMessage, HumanMessage, ToolMessage\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "examples = [\n",
    "    HumanMessage(\n",
    "        \"What's the product of 317253 and 128472 plus four\", name=\"example_user\"\n",
    "    ),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[\n",
    "            {\"name\": \"Multiply\", \"args\": {\"x\": 317253, \"y\": 128472}, \"id\": \"1\"}\n",
    "        ],\n",
    "    ),\n",
    "    ToolMessage(\"16505054784\", tool_call_id=\"1\"),\n",
    "    AIMessage(\n",
    "        \"\",\n",
    "        name=\"example_assistant\",\n",
    "        tool_calls=[{\"name\": \"Add\", \"args\": {\"x\": 16505054784, \"y\": 4}, \"id\": \"2\"}],\n",
    "    ),\n",
    "    ToolMessage(\"16505054788\", tool_call_id=\"2\"),\n",
    "    AIMessage(\n",
    "        \"The product of 317253 and 128472 plus four is 16505054788\",\n",
    "        name=\"example_assistant\",\n",
    "    ),\n",
    "]\n",
    "\n",
    "system = \"\"\"You are bad at math but are an expert at using a calculator. \n",
    "\n",
    "Use past tool usage as an example of how to correctly use the tools.\"\"\"\n",
    "few_shot_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", system),\n",
    "        *examples,\n",
    "        (\"human\", \"{query}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = {\"query\": RunnablePassthrough()} | few_shot_prompt | llm_with_tools\n",
    "chain.invoke(\"Whats 119 times 8 minus 20\").tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50608aee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
