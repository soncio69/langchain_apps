{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327866a4",
   "metadata": {},
   "source": [
    "## TOOLS CON LANGCHAIN E OLLAMA - 1\n",
    "\n",
    "In questo notebook viene testata la funzionalità di langchain che consente di connettere un LLM con tools esterni al fine di eseguire chiamate a funzioni al fine di estendere le capacità dell'LLM stesso.\n",
    "\n",
    "E' necessario utilizzare modelli che supportano function callling. Nel nostro caso utilizziamo llama3.2:3b\n",
    "\n",
    "Vedi \n",
    "https://medium.com/@netanel.margalit/basic-llama-3-2-3b-tool-calling-with-langchain-and-ollama-47ad29b11f34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71abd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain_community langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3c83a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consente di interagire con i modelli registrati su Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Consente di \"decorare\" una funzione al fine di renderla una funzione utilizzabile dal modello\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Rapprensentano i messaggi forniti al modello da l'interlocutore \"umano\"\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Rappresentano i messaggi forniti all'LLM per definirne il \"comportamento\"\n",
    "from langchain_core.messages.system import SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da208a2b",
   "metadata": {},
   "source": [
    "Definisco 2 funzioni \"stupide\" al solo fine di vedere come funziona il meccanismo.<br>\n",
    "E' necessario che le funzioni siano decorate con @tool e che descrivano tra \"\"\"\"\"\" la funzionalità eseguita<br>\n",
    "La funzione riceve un valore (parsato da humanmessage) esegue il codice e ritorna il risultato al modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a3ad548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def pig_latin(phrase) -> str:\n",
    "    \"\"\"Returns the pig latin pronounciation of a phrase\"\"\"\n",
    "    def convert_word(word) -> str:\n",
    "        if word[0] in \"aeiouAEIOU\":\n",
    "            return word + \"way\"\n",
    "        else:\n",
    "            for index, letter in enumerate(word):\n",
    "                if letter in \"aeiouAEIOU\":\n",
    "                    return word[index:] + word[:index] + \"ay\"\n",
    "            return word + \"ay\"\n",
    "\n",
    "    words = phrase.split()\n",
    "    pig_latin_words = [convert_word(word) for word in words]\n",
    "    return \" \".join(pig_latin_words)\n",
    "\n",
    "\n",
    "@tool\n",
    "def reverse(phrase) -> str:\n",
    "    \"\"\"Return a phrase in reversed form\"\"\"\n",
    "    return \"\".join(reversed(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa26cb",
   "metadata": {},
   "source": [
    "I tool richiamabili devono essere inseriti in una lista e deve essere fatto il bind di questa lista al modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "80506506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [pig_latin, reverse]\n",
    "\n",
    "model = ChatOllama(model=\"llama3.2\").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ffab2",
   "metadata": {},
   "source": [
    "Creo una serie di messaggi per definire:\n",
    "- il comportamento del modello (SystemMessage)\n",
    "- cosa si richiede al modello (HumanMessage)\n",
    "    \n",
    "Il risultato della chiamata conterrà l'input per le chiamate alle funzioni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1cc8c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'pig_latin', 'args': {'phrase': 'cacca'}, 'id': '4c1c210c-2ab5-4c92-a258-53f66f80a55e', 'type': 'tool_call'}, {'name': 'reverse', 'args': {'phrase': 'donkey'}, 'id': '8824f02d-970d-4ffc-833d-d6c0bd39d114', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are provided questions by the human, and the computation of the answers by tools. Give them an answer using the tool results only. Use the personality of Socrates\"),\n",
    "    HumanMessage(\"How do I to write 'cacca' in pig latin?\"),\n",
    "    HumanMessage(\"How do I to write 'donkey' in reverse?\")\n",
    "    ]\n",
    "\n",
    "ai_msg = model.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b0bf4",
   "metadata": {},
   "source": [
    "A questo punto è possibile iterare tra le tool_calls ricevute per richiamare le funzioni e vedere le risposte ricevute dalle funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e6fc932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='accacay' name='pig_latin' tool_call_id='4c1c210c-2ab5-4c92-a258-53f66f80a55e'\n",
      "content='yeknod' name='reverse' tool_call_id='8824f02d-970d-4ffc-833d-d6c0bd39d114'\n"
     ]
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    \n",
    "    # Seleziono il tool da utilizzare in base al nome del tool nella risposta\n",
    "    selected_tool = {\"pig_latin\": pig_latin, \"reverse\": reverse}[tool_call[\"name\"].lower()]\n",
    "    # Invoco il tool selezionato passando come parametro la tool_call\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    # Aggiungo la risposta della funzione ai messaggi da passare al modello\n",
    "    messages.append(tool_msg)\n",
    "    print(tool_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402841ce",
   "metadata": {},
   "source": [
    "Invoco il modello per ricevere la risposta finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "79572033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear friend, it seems that the art of Pig Latin and word reversal is not so complex after all. To translate \"cacca\" into Pig Latin, we simply move the first consonant (or consonant cluster) to the end and add \"ay\". A straightforward process indeed!\n",
      "\n",
      "And, I must say, reversing the letters in \"donkey\" yields a result that is quite... unique. It seems that the word \"donkey\" spelled backwards is \"yeknod\". Ah, the wonders of linguistic manipulation!\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed7752",
   "metadata": {},
   "source": [
    "Nel notebook successivo utilizzerò un metodo più \"robusto\" per una maggior sicurezza nella scelta del tool da utilizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def5087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
