{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "327866a4",
   "metadata": {},
   "source": [
    "## TOOLS CON LANGCHAIN E OLLAMA - 1\n",
    "\n",
    "In questo notebook viene testata la funzionalità di langchain che consente di connettere un LLM con tools esterni al fine di eseguire chiamate a funzioni al fine di estendere le capacità dell'LLM stesso.\n",
    "\n",
    "E' necessario utilizzare modelli che supportano function callling. Nel nostro caso utilizziamo llama3.2:3b\n",
    "\n",
    "Vedi \n",
    "https://medium.com/@netanel.margalit/basic-llama-3-2-3b-tool-calling-with-langchain-and-ollama-47ad29b11f34\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71abd3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install langchain langchain_community langchain-ollama ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c83a430",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Consente di interagire con i modelli registrati su Ollama\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "# Consente di \"decorare\" una funzione al fine di renderla una funzione utilizzabile dal modello\n",
    "from langchain_core.tools import tool\n",
    "\n",
    "# Rapprensentano i messaggi forniti al modello da l'interlocutore \"umano\"\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Rappresentano i messaggi forniti all'LLM per definirne il \"comportamento\"\n",
    "from langchain_core.messages.system import SystemMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da208a2b",
   "metadata": {},
   "source": [
    "Definisco 2 funzioni \"stupide\" al solo fine di vedere come funziona il meccanismo.<br>\n",
    "E' necessario che le funzioni siano decorate con @tool e che descrivano tra \"\"\"\"\"\" la funzionalità eseguita<br>\n",
    "La funzione riceve un valore (parsato da humanmessage) esegue il codice e ritorna il risultato al modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ad548f",
   "metadata": {},
   "outputs": [],
   "source": [
    "@tool\n",
    "def pig_latin(phrase) -> str:\n",
    "    \"\"\"Returns the pig latin pronounciation of a phrase\"\"\"\n",
    "    def convert_word(word) -> str:\n",
    "        if word[0] in \"aeiouAEIOU\":\n",
    "            return word + \"way\"\n",
    "        else:\n",
    "            for index, letter in enumerate(word):\n",
    "                if letter in \"aeiouAEIOU\":\n",
    "                    return word[index:] + word[:index] + \"ay\"\n",
    "            return word + \"ay\"\n",
    "\n",
    "    words = phrase.split()\n",
    "    pig_latin_words = [convert_word(word) for word in words]\n",
    "    return \" \".join(pig_latin_words)\n",
    "\n",
    "\n",
    "@tool\n",
    "def reverse(phrase) -> str:\n",
    "    \"\"\"Return a phrase in reversed form\"\"\"\n",
    "    return \"\".join(reversed(phrase))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5aa26cb",
   "metadata": {},
   "source": [
    "I tool richiamabili devono essere inseriti in una lista e deve essere fatto il bind di questa lista al modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80506506",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [pig_latin, reverse]\n",
    "\n",
    "model = ChatOllama(model=\"llama3.2\").bind_tools(tools)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "801ffab2",
   "metadata": {},
   "source": [
    "Creo una serie di messaggi per definire:\n",
    "- il comportamento del modello (SystemMessage)\n",
    "- cosa si richiede al modello (HumanMessage)\n",
    "    \n",
    "Il risultato della chiamata conterrà l'input per le chiamate alle funzioni "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1cc8c251",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'name': 'pig_latin', 'args': {'phrase': 'cacca'}, 'id': 'cd628340-2422-405a-8076-14987e174e72', 'type': 'tool_call'}, {'name': 'reverse', 'args': {'phrase': 'donkey'}, 'id': '55be79cd-0f5f-462b-9fa5-e2b8189bea67', 'type': 'tool_call'}]\n"
     ]
    }
   ],
   "source": [
    "messages = [\n",
    "    SystemMessage(\"You are provided questions by the human, and the computation of the answers by tools. Give them an answer using the tool results only. Use the personality of Socrates\"),\n",
    "    HumanMessage(\"How do I to write 'cacca' in pig latin?\"),\n",
    "    HumanMessage(\"How do I to write 'donkey' in reverse?\")\n",
    "    ]\n",
    "\n",
    "ai_msg = model.invoke(messages)\n",
    "\n",
    "print(ai_msg.tool_calls)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a9b0bf4",
   "metadata": {},
   "source": [
    "A questo punto è possibile iterare tra le tool_calls ricevute per richiamare le funzioni e vedere le risposte ricevute dalle funzioni"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6fc932a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='accacay' name='pig_latin' tool_call_id='cd628340-2422-405a-8076-14987e174e72'\n",
      "content='yeknod' name='reverse' tool_call_id='55be79cd-0f5f-462b-9fa5-e2b8189bea67'\n"
     ]
    }
   ],
   "source": [
    "for tool_call in ai_msg.tool_calls:\n",
    "    \n",
    "    # Seleziono il tool da utilizzare in base al nome del tool nella risposta\n",
    "    selected_tool = {\"pig_latin\": pig_latin, \"reverse\": reverse}[tool_call[\"name\"].lower()]\n",
    "    # Invoco il tool selezionato passando come parametro la tool_call\n",
    "    tool_msg = selected_tool.invoke(tool_call)\n",
    "    # Aggiungo la risposta della funzione ai messaggi da passare al modello\n",
    "    messages.append(tool_msg)\n",
    "    print(tool_msg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "402841ce",
   "metadata": {},
   "source": [
    "Invoco il modello per ricevere la risposta finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79572033",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dear friend, it seems you have asked me two questions, one about Pig Latin and the other about reversing words. Let us examine them together.\n",
      "\n",
      "To write 'cacca' in Pig Latin, we must follow the rules of Pig Latin, which involves moving the first consonant (or consonant cluster) of a word to the end of the word and adding the sound \"ay\". In this case, the word 'cacca' begins with a vowel, so we simply add \"way\" at the end. Thus, 'cacca' in Pig Latin is indeed 'accacay'.\n",
      "\n",
      "And now, let us turn our attention to reversing the word 'donkey'. To do so, we must spell it out letter by letter: d-o-n-k-e-y. We then take each letter and move it to the opposite end of the sequence: y-e-k-n-o-d. And thus, the reversed word is indeed 'yeknod'.\n",
      "\n",
      "But tell me, dear friend, how did you come across these questions? What is it about Pig Latin and word reversal that piques your interest?\n"
     ]
    }
   ],
   "source": [
    "print(model.invoke(messages).content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98ed7752",
   "metadata": {},
   "source": [
    "Nel notebook successivo utilizzerò un metodo più \"robusto\" per una maggior sicurezza nella scelta del tool da utilizzare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4def5087",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:langchain_env]",
   "language": "python",
   "name": "conda-env-langchain_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
